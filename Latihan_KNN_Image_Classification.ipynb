{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Latihan KNN Image Classification",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFYNAb0nD2W-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXNltjTkD49U",
        "outputId": "cff4fda3-c58a-434b-d7e0-a764d02bb732"
      },
      "source": [
        "!unzip /content/gdrive/MyDrive/datasets/Cat and Dogs/Cat and dogs.zip -d /content/gdrive/MyDrive/datasets/Cat and Dogs"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test1.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/test1.zip or\n",
            "        /content/test1.zip.zip, and cannot find /content/test1.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQOstDJa-v_h",
        "outputId": "79148906-fea4-4d0c-98fb-06baa9bb413f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTdKEQIb_YB3",
        "outputId": "44c31920-6fc9-481b-f59d-f9cee06a39e4"
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/datasets/Cats and Dogs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/gdrive/My Drive/datasets/animals': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz93v14PoDHM"
      },
      "source": [
        "IMPORT LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGVLHfBr1mZQ"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HViBdxd0_5TV"
      },
      "source": [
        "LOAD DATASET "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4VtPi6UnqxX"
      },
      "source": [
        "class SimpleDatasetLoader: #Kelas untuk load dataset\n",
        "    def __init__(self, preprocessors=None):\n",
        "        \"\"\"\n",
        "        :param preprocessors: List of image preprocessors\n",
        "        \"\"\"\n",
        "        self.preprocessors = preprocessors\n",
        "\n",
        "        if self.preprocessors is None:\n",
        "            self.preprocessors = []\n",
        "\n",
        "    #Load dataset untuk dilakukan preprocessing\n",
        "    def load(self, image_paths, verbose=-1):\n",
        "        \"\"\"\n",
        "        :param image_paths: List of image paths\n",
        "        :param verbose: Parameter for printing information to console\n",
        "        :return: Tuple of data and labels\n",
        "        \"\"\"\n",
        "        data, labels = [], []\n",
        "\n",
        "        for i, image_path in enumerate(image_paths):\n",
        "            image = cv2.imread(image_path)\n",
        "            label = image_path.split(os.path.sep)[-2]\n",
        "\n",
        "            if self.preprocessors is not None:\n",
        "                for p in self.preprocessors:\n",
        "                    image = p.preprocess(image)\n",
        "\n",
        "            data.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "            if verbose > 0 and i > 0 and (i+1) % verbose == 0:\n",
        "                print('[INFO]: Processed {}/{}'.format(i+1, len(image_paths)))\n",
        "\n",
        "        return (np.array(data), np.array(labels))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv8gK5Xe4s0I"
      },
      "source": [
        "Menggunakan Simple Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0XrShHy4G16"
      },
      "source": [
        "#Kelas untuk preprocessor\n",
        "class SimplePreprocessor:\n",
        "    def __init__(self, width, height, interpolation=cv2.INTER_AREA):\n",
        "        \"\"\"\n",
        "        :param width: Image width\n",
        "        :param height: Image height\n",
        "        :param interpolation: Interpolation algorithm\n",
        "        \"\"\"\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.interpolation = interpolation\n",
        "\n",
        "    def preprocess(self, image): #Resize image tanpa memperhatikan ratio\n",
        "        \"\"\"\n",
        "        :param image: Image\n",
        "        :return: Re-sized image\n",
        "        \"\"\"\n",
        "        return cv2.resize(image, (self.width, self.height), interpolation=self.interpolation)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqu2HjunojTl"
      },
      "source": [
        "IMPORT LIBRARY KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Fvmja-9Zag"
      },
      "source": [
        "from imutils import paths\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from __main__ import SimplePreprocessor\n",
        "from __main__ import SimpleDatasetLoader"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrGDuqE5otET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "59d0a461-ea19-4af9-bee6-9efe3d0a759e"
      },
      "source": [
        "# Get list of image paths\n",
        "image_paths = list(paths.list_images(\"/content/gdrive/My Drive/datasets/animals\"))\n",
        "\n",
        "# Inisiasi SimplePreprocessor dan SimpleDatasetLoader serta load data dan labels\n",
        "print('[INFO]: Images Scanning......')\n",
        "sp = SimplePreprocessor(32, 32)\n",
        "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
        "(data, labels) = sdl.load(image_paths, verbose=500)\n",
        "\n",
        "# Reshape from (3000, 32, 32, 3) to (3000, 32*32*3=3072)\n",
        "data = data.reshape((data.shape[0], 3072))\n",
        "\n",
        "# Print informasi memori\n",
        "print('[INFO]: Features Matrix: {:.1f}MB'.format(float(data.nbytes / 1024*1000.0)))\n",
        "\n",
        "# Encode labels as integers\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# Split data test dan data train\n",
        "(train_x, test_x, train_y, test_y) = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# TRain dan evaluasi model KNN\n",
        "print('[INFO]: Classification is on the way....')\n",
        "model = KNeighborsClassifier(n_neighbors=7,\n",
        "                             n_jobs=1)\n",
        "model.fit(train_x, train_y)\n",
        "print(classification_report(test_y, model.predict(test_x),\n",
        "                            target_names=le.classes_))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Images Scanning......\n",
            "[INFO]: Features Matrix: 0.0MB\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b6a277a36e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Split data test dan data train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# TRain dan evaluasi model KNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[0;32m-> 2423\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2424\u001b[0m     )\n\u001b[1;32m   2425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m             \u001b[0;34m\"aforementioned parameters.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2102\u001b[0m         )\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zbyD81WB0fr"
      },
      "source": [
        "MENCARI NILAI K TERBAIK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPRdFy6povgK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "73395081-f06f-41bc-bb96-05d92c6149e1"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np \n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=2,n_jobs=1)\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "accuracy = accuracy_score(model.predict(test_x), test_y)\n",
        "print(accuracy)\n",
        "n_neighbors = np.array([7,8,9,10,12,15,20])\n",
        "param_grid = dict(n_neighbors=n_neighbors)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid.fit(train_x, train_y)\n",
        "print(grid.best_score_)\n",
        "print(grid.best_estimator_.n_neighbors)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e3f1f80ad611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCiAjiD4ozC6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#print(grid.cv_results_)\n",
        "print(grid.param_grid)\n",
        "print(grid.best_score_)\n",
        "print(grid.scorer_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1GO8OyCkLx"
      },
      "source": [
        "FASTER KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XRPzC0yCjs6"
      },
      "source": [
        " #algorithm='ball_tree'\n",
        " #its fs\n",
        "  \n",
        "from imutils import paths\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from __main__ import SimplePreprocessor\n",
        "from __main__ import SimpleDatasetLoader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get list of image paths\n",
        "image_paths = list(paths.list_images(\"/content/gdrive/My Drive/datasets/animals\"))\n",
        "\n",
        "# Initialize SimplePreprocessor and SimpleDatasetLoader and load data and labels\n",
        "print('[INFO]: Images loading....')\n",
        "sp = SimplePreprocessor(32, 32)\n",
        "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
        "(data, labels) = sdl.load(image_paths, verbose=500)\n",
        "\n",
        "# Reshape from (3000, 32, 32, 3) to (3000, 32*32*3=3072)\n",
        "data = data.reshape((data.shape[0], 3072))\n",
        "\n",
        "# Print information about memory consumption\n",
        "print('[INFO]: Features Matrix: {:.1f}MB'.format(float(data.nbytes / 1024*1000.0)))\n",
        "\n",
        "# Encode labels as integers\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# Split data into training (75%) and testing (25%) data\n",
        "(train_x, test_x, train_y, test_y) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train and evaluate the k-NN classifier on the raw pixel intensities\n",
        "print('[INFO]: Classification starting....')\n",
        "model = KNeighborsClassifier(n_neighbors=7,\n",
        "                             n_jobs=1,algorithm='kd_tree')\n",
        "model.fit(train_x, train_y)\n",
        "print(classification_report(test_y, model.predict(test_x),\n",
        "                            target_names=le.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}